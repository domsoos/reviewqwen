{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a99572-27d1-4840-ad93-469ba6423215",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from PIL import Image\n",
    "\n",
    "###############################################################################\n",
    "# PART 1: MODEL INITIALIZATION\n",
    "###############################################################################\n",
    "def initialize_model(model_path: str):\n",
    "    \"\"\"\n",
    "    Initializes the processor and model from the local directory.\n",
    "    Uses `device_map=\"auto\"` to automatically distribute layers across GPUs if available.\n",
    "    \"\"\"\n",
    "    processor = AutoProcessor.from_pretrained(model_path)\n",
    "    model = AutoModelForImageTextToText.from_pretrained(\n",
    "        model_path,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    return processor, model\n",
    "###############################################################################\n",
    "# PART 2: DATA PREPARATION (images, text, prompt)\n",
    "###############################################################################\n",
    "def prepare_data(buyer_image_path: str, seller_image_path: str):\n",
    "    \"\"\"\n",
    "    Loads and resizes the images, defines buyer/seller descriptions, \n",
    "    constructs chat messages, and prepares the model inputs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load & resize images\n",
    "        buyer_image = Image.open(buyer_image_path).convert(\"RGB\").resize((524, 524))\n",
    "        seller_image = Image.open(seller_image_path).convert(\"RGB\").resize((524, 524))\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading images: {e}\")\n",
    "\n",
    "    # Example buyer/seller descriptions\n",
    "    buyer_description = (\n",
    "          \"\"\"I was excited to open the package as soon as it arrived. The build feels solid yet not overly heavy, which is great for my small nightstand. I especially like how the display is easy on the eyes—even in the middle of the night, it doesn’t light up the entire room. My favorite part is how seamlessly it charges through my wallet case. It’s just so hassle-free! I’m actually thinking about grabbing another one for the office.\n",
    "\n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "    seller_description = (\n",
    "\"\"\" seller description\n",
    "\n",
    "\"\"\"\n",
    "    )\n",
    "    \n",
    "    prompt = (\n",
    "        \"Analyze the alignment between the seller's promises and the buyer's experience by examining the seller's description, the buyer's review, and any accompanying images provided by both. Determine if the visual appearance in the seller’s image matches the product in the buyer’s image and whether the seller’s description aligns with the buyer’s feedback. Identify any irrelevant comments in the buyer's review that praise the product based on personal preferences rather than promised features. Additionally, evaluate if there are any discrepancies between what the seller promised and what the buyer experienced, and assess whether the buyer’s review reflects satisfaction, dissatisfaction, or a personal opinion about the product. Provide a clear conclusion based on your findings.\"\n",
    "    )\n",
    "    \n",
    "    # Construct messages\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": buyer_image},\n",
    "                {\"type\": \"text\", \"text\": buyer_description},\n",
    "                {\"type\": \"image\", \"image\": seller_image},\n",
    "                {\"type\": \"text\", \"text\": seller_description},\n",
    "                {\"type\": \"text\", \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    return buyer_image, seller_image, messages\n",
    "\n",
    "###############################################################################\n",
    "# PART 3: GENERATE AND DECODE MODEL OUTPUT\n",
    "###############################################################################\n",
    "def generate_analysis(processor, model, buyer_image, seller_image, messages):\n",
    "    \"\"\"\n",
    "    Uses the loaded processor and model to transform the messages into a suitable format,\n",
    "    then generates and decodes the final output.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = processor.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        if text is None:\n",
    "            raise ValueError(\"Generated text from apply_chat_template is None.\")\n",
    "\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=[buyer_image, seller_image],\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=550,\n",
    "            temperature=0.7,\n",
    "            repetition_penalty=1.2,\n",
    "            top_k=50,\n",
    "            top_p=0.9\n",
    "        )\n",
    "\n",
    "        generated_ids_trimmed = [\n",
    "            out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids_trimmed,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "\n",
    "        return output_text[0]\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error during processing or inference: {e}\")\n",
    "\n",
    "###############################################################################\n",
    "# MAIN EXECUTION EXAMPLE\n",
    "###############################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"qwen_model\"\n",
    "\n",
    "    processor, model = initialize_model(model_path)\n",
    "\n",
    "    buyer_image_path = \"image/path.jpg\"\n",
    "    seller_image_path = \"image/path.jpg\"\n",
    "    buyer_image, seller_image, messages = prepare_data(buyer_image_path, seller_image_path)\n",
    "\n",
    "    analysis_text = generate_analysis(processor, model, buyer_image, seller_image, messages)\n",
    "    print(\"Generated Structured Analysis:\\n\", analysis_text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
