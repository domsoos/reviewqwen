{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a99572-27d1-4840-ad93-469ba6423215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "from PIL import Image\n",
    "\n",
    "###############################################################################\n",
    "# 1) SETUP: MODEL & PROCESSOR\n",
    "###############################################################################\n",
    "model_path = \"qwen_model\"  \n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_path)\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"  # Distribute across GPUs automatically if available\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 2) EXAMPLE CASES: TEXT-ONLY CHAIN OF THOUGHT\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"buyer_image_path\": \"Buyer_image_1.jpg\",\n",
    "        \"seller_image_path\": \"Seller_image_1.jpg\",\n",
    "        \"buyer_review\": \"Example buyer review\",\n",
    "        \"seller_description\": \"example seller description\",\n",
    "        \"expected_output\": \"example expected output\"\n",
    "    },\n",
    "    {\n",
    "        \"buyer_image_path\": \"Buyer_image_2.jpg\",\n",
    "        \"seller_image_path\": \"Seller_image_2.jpg\",\n",
    "        \"buyer_review\": \"Example buyer review\",\n",
    "        \"seller_description\": \"example seller description\",\n",
    "        \"expected_output\": \"example expected output\"\n",
    "    },\n",
    "    # Add more examples as needed\n",
    "    \n",
    "]\n",
    "\n",
    "###############################################################################\n",
    "# 3) BUILD THE EXAMPLE TEXT\n",
    "###############################################################################\n",
    "\n",
    "example_text_blocks = []\n",
    "for i, ex in enumerate(examples, start=1):\n",
    "    block = (\n",
    "        f\"Example {i}:\\n\"\n",
    "        f\"Buyer Review:\\n{ex['buyer_review']}\\n\\n\"\n",
    "        f\"Seller Description:\\n{ex['seller_description']}\\n\\n\"\n",
    "        f\"Expected Output:\\n{ex['expected_output']}\\n\"\n",
    "        f\"{'-'*40}\\n\"\n",
    "    )\n",
    "    example_text_blocks.append(block)\n",
    "\n",
    "# Combine all example blocks into a single string\n",
    "examples_text_combined = \"\\n\".join(example_text_blocks)\n",
    "\n",
    "###############################################################################\n",
    "# 4) ACTUAL CASE INPUT (WITH 2 REAL IMAGES)\n",
    "###############################################################################\n",
    "buyer_image_path = \"buyerimage.jpg\"\n",
    "seller_image_path = \"sellerimage.jpg\"\n",
    "\n",
    "try:\n",
    "    buyer_image = Image.open(buyer_image_path).convert(\"RGB\").resize((524, 524))\n",
    "    seller_image = Image.open(seller_image_path).convert(\"RGB\").resize((524, 524))\n",
    "except Exception as e:\n",
    "    print(f\"Error loading actual images: {e}\")\n",
    "    raise\n",
    "\n",
    "# Define the buyer's review, seller's description, and final prompt\n",
    "actual_buyer_review = (\n",
    "\"\"\" Actual buyer review\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "actual_seller_description = (\n",
    "    \"\"\"Actual seller reveiw\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "analysis_prompt = (\n",
    "    \"Actual prompt\"\n",
    ")\n",
    "\n",
    "###############################################################################\n",
    "# 5) BUILD THE FINAL MULTI-MODAL MESSAGE\n",
    "###############################################################################\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": (\n",
    "                    \"Below are multiple chain-of-thought examples for reference:\\n\\n\"\n",
    "                    f\"{examples_text_combined}\\n\"\n",
    "                    \"Now, here is the new case to analyze:\\n\\n\"\n",
    "                )\n",
    "            },\n",
    "            {\"type\": \"image\", \"image\": buyer_image},\n",
    "            {\"type\": \"text\", \"text\": f\"Buyer Review:\\n{actual_buyer_review}\\n\\n\"},\n",
    "            {\"type\": \"image\", \"image\": seller_image},\n",
    "            {\"type\": \"text\", \"text\": f\"Seller Description:\\n{actual_seller_description}\\n\\n\"},\n",
    "            {\"type\": \"text\", \"text\": analysis_prompt},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "###############################################################################\n",
    "# 6) CONSTRUCT THE FINAL TEXT & PREPARE MODEL INPUT\n",
    "###############################################################################\n",
    "try:\n",
    "    text_input = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    if text_input is None:\n",
    "        raise ValueError(\"Generated text from apply_chat_template is None.\")\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text_input],\n",
    "        images=[buyer_image, seller_image],\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True\n",
    "    )\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    ###############################################################################\n",
    "    # 7) GENERATE OUTPUT (CHAIN OF THOUGHT RESPONSE)\n",
    "    ###############################################################################\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1500,\n",
    "        temperature=0.7,\n",
    "        repetition_penalty=1.1,\n",
    "        top_k=50,\n",
    "        top_p=0.9\n",
    "    )\n",
    "\n",
    "    generated_ids_trimmed = [\n",
    "        out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs[\"input_ids\"], generated_ids)\n",
    "    ]\n",
    "\n",
    "    # Decode the final text\n",
    "    output_text = processor.batch_decode(\n",
    "        generated_ids_trimmed,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    print(\"Model's Chain-of-Thought Analysis:\\n\", output_text[0])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error during processing or inference: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
